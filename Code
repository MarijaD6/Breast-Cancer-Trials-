from google.colab import drive 
drive.mount('/content/drive')

import tensorflow as tf
print(tf.__version__) 
print(tf.keras.__version__)

import tensorflow as tf 
print(tf.config.list_physical_devices('GPU'))

!pip install imgaug

!pip install numpy==1.26.4

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import EfficientNetB5
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau
from sklearn.utils.class_weight import compute_class_weight
import numpy as np
import matplotlib.pyplot as plt
import os
import shutil
import glob
from sklearn.model_selection import train_test_split
import imgaug.augmenters as iaa
import albumentations as A

# Дефинира основен извор на податоци
from google.colab import drive
drive.mount('/content/drive')
main_directory = '/content/drive/My Drive/Colab_Notebooks'
data_folder = os.path.join('/content/drive/My Drive','breast')

# Читање на податоци
def collect_png_images(root_dir):
    png_images = []

    for dirpath, _, filenames in os.walk(root_dir):
        for file in filenames:
            if file.lower().endswith('.png'):
                full_path = os.path.join(dirpath, file)
                png_images.append(full_path)

    return png_images

magnifications = ['40X', '100X', '200X', '400X']
classes = ['benign', 'malignant']
image_counts = {cls: {mag: 0 for mag in magnifications} for cls in classes}


for cls in classes:
    class_base = os.path.join(data_folder, cls, 'SOB')
    print(f"\nScanning {cls} in path: {class_base}")

    if not os.path.exists(class_base):
        print(f"ERROR: Path does not exist - {class_base}")
        continue

    for root, dirs, files in os.walk(class_base):
        for mag in magnifications:
            if root.endswith(mag):
                count = len([f for f in files if f.lower().endswith('.png')])
                image_counts[cls][mag] += count
                print(f"  Found {count} images in: {root}")


print("\n==== Image Counts Per Class and Magnification ====")
for cls in image_counts:
    print(f"\nClass: {cls}")
    for mag in magnifications:
        print(f"  {mag}: {image_counts[cls][mag]} images")


training_folder = os.path.join(main_directory, 'train')
validation_folder = os.path.join(main_directory, 'validation')

for folder in [training_folder, validation_folder]:
    for cls in classes:
        os.makedirs(os.path.join(folder, cls), exist_ok=True)

benign_images = collect_png_images(os.path.join(data_folder, 'benign'))
malignant_images = collect_png_images(os.path.join(data_folder, 'malignant'))
print(f"Found {len(benign_images)} benign images.")
print(f"Found {len(malignant_images)} malignant images.")

# Дефинира потфолдери за бенигно и малигно 
benign_dir = os.path.join(main_directory, 'benign')
malignant_dir = os.path.join(main_directory, 'malignant')

#  Дефинира фолдери за тренинг и валдиација
train_dir = os.path.join(main_directory, 'train')
val_dir = os.path.join(main_directory, 'validation')

os.makedirs(train_dir, exist_ok=True)
os.makedirs(val_dir, exist_ok=True)

#  Креира потфолдери за бенигно и малигно во тренинг и валидација 
for category in ['benign', 'malignant']:
    os.makedirs(os.path.join(train_dir, category), exist_ok=True)
    os.makedirs(os.path.join(val_dir, category), exist_ok=True)

# Фунцкија на поделба на податоци и копија во соодветните фолдери
def split_and_copy_images(source_dir, train_dest_dir, val_dest_dir, split_ratio=0.2):
    image_files = glob.glob(os.path.join(source_dir, '**', '*.png'), recursive=True)
    train_files, val_files = train_test_split(image_files, test_size=split_ratio, random_state=42)

    for file in train_files:
        shutil.copy(file, train_dest_dir)

    for file in val_files:
        shutil.copy(file, val_dest_dir)


# Функција за поделба на податоците која ги копира во точните бази
def split_and_copy_images_from_list(image_files, training_dest_dir, validation_dest_dir, split_ratio=0.2):
    # Split the list
    training_files, validation_files = train_test_split(image_files, test_size=split_ratio, random_state=42)


    os.makedirs(training_dest_dir, exist_ok=True)
    os.makedirs(validation_dest_dir, exist_ok=True)

    # Копирање на тренинг-податоци
    for file in training_files:
        filename = os.path.basename(file)
        dest_path = os.path.join(training_dest_dir, filename)
        shutil.copy(file, dest_path)

    # Копирање на валидација-податоци
    for file in validation_files:
        filename = os.path.basename(file)
        dest_path = os.path.join(validation_dest_dir, filename)
        shutil.copy(file, dest_path)

    print(f"✔️ Copied {len(training_files)} images to {training_dest_dir}")
    print(f"✔️ Copied {len(validation_files)} images to {validation_dest_dir}")


#  Генерална аугментација на подтоци 
training_datagen = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    brightness_range=[0.9, 1.1],
)

val_datagen = ImageDataGenerator (rescale=1./255)

#  Креирање генератори за генерални податоци 
training_generator = training_datagen.flow_from_directory(
    training_folder,
    target_size=(224, 224),
    batch_size=16 ,
    class_mode='binary'
)

validation_datagen = ImageDataGenerator(rescale=1./255)
validation_generator = validation_datagen.flow_from_directory(
    validation_folder,  # This is your directory path
    target_size=(224, 224),
    batch_size=16,
    class_mode='binary'
)

from PIL import Image
import os

bad_images = []
for folder in [train_dir, val_dir]:
    for root, _, files in os.walk(folder):
        for file in files:
            if file.lower().endswith(('png', 'jpg', 'jpeg')):
                fpath = os.path.join(root, file)
                try:
                    img = Image.open(fpath)
                    img.verify()
                except Exception as e:
                    print(f"Deleting bad image: {fpath}")
                    bad_images.append(fpath)

print(f"Found {len(bad_images)} unreadable images.")

for f in bad_images:
    os.remove(f)

# Калкулира број на слики во секоја класа
class_counts = {category: len(glob.glob(os.path.join(train_dir, category, '*.png'))) for category in ['benign', 'malignant']}
print(class_counts)

# Детерминира помалку застапени класи
mean_count = np.mean(list(class_counts.values()))
underrepresented_class = [category for category, count in class_counts.items() if count < mean_count]
print(f"Underrepresented class: {underrepresented_class}")


# Костумизира аугментациска низа на процесни елементи
augmentation_pipeline = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.2),
    A.Rotate(limit=45, p=0.5),
    A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5),
    A.GaussianBlur(blur_limit=(3, 7), p=0.3),
    A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),
    A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=30, p=0.5)
])
# Аугментира и додава фотографии за помалку застапените класи
for category in underrepresented_class:
    category_dir = os.path.join(training_folder, category)
    images = glob.glob(os.path.join(category_dir, '*.png'))

    for img_path in images:
        img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))
        img_array = tf.keras.preprocessing.image.img_to_array(img).astype(np.uint8)

        num_aug = int(mean_count / len(images))

        for i in range(num_aug):
            augmented = augmentation_pipeline(image=img_array)
            augmented_img = augmented['image']

            augmented_pil = tf.keras.preprocessing.image.array_to_img(augmented_img)
            aug_filename = f"aug_{i}_{os.path.basename(img_path)}"
            augmented_pil.save(os.path.join(category_dir, aug_filename))

# Рекреира генератори после аугментација
training_generator = training_datagen.flow_from_directory(
    training_folder,
    target_size=(224, 224),
    batch_size=16,
    class_mode='binary'
)

validation_generator = validation_datagen.flow_from_directory(
    validation_folder,
    target_size=(224, 224),
    batch_size=16,
    class_mode='binary'
)

!pip install --upgrade tensorflow
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, GlobalAveragePooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau
import os, shutil
from tensorflow.keras.applications import EfficientNetB5
from tensorflow.keras.optimizers import Adam
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import confusion_matrix, classification_report
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import seaborn as sns
from sklearn.model_selection import train_test_split
import shutil
import albumentations as A

# Дефинира основен извор на податоци
from google.colab import drive
drive.mount('/content/drive')
main_directory = '/content/drive/My Drive/Colab_Notebooks'
data_folder = os.path.join('/content/drive/My Drive','breast')

# Креирај база за тренирање и валидација на податоците
training_folder = os.path.join(main_directory, 'train')
validation_folder = os.path.join(main_directory, 'validation')

os.makedirs(training_folder, exist_ok=True)
os.makedirs(validation_folder, exist_ok=True)

#Аугментација на генерална дата за бинарна класификација 
training_datagen = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    brightness_range=[0.9, 1.1],
)

validation_datagen = ImageDataGenerator(rescale=1./255)

train_generator = training_datagen.flow_from_directory(
    training_folder,
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary'
)

validation_generator = validation_datagen.flow_from_directory(
    validation_folder,
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary'
)

#  Дефинирање на модел за бинарна класификација 
model = Sequential([
    EfficientNetB5(input_shape=(224, 224, 3), include_top=False, weights='imagenet'),
    GlobalAveragePooling2D(),
    Dropout(0.8),
    Dense(1, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.01))
])

model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])

# Дефинира callback 
checkpoint_filepath = '/content/drive/MyDrive/efficientnet_checkpoints/best_model.keras'
checkpoint = ModelCheckpoint(
    filepath=checkpoint_filepath,
    save_weights_only=False,
    monitor='val_loss',
    mode='min',
    save_best_only=True,
    verbose=1
)

early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)

def scheduler(epoch, lr):
    if epoch < 10:
        return lr
    else:
        return lr * tf.math.exp(-0.1)

lr_callback = LearningRateScheduler(scheduler)

#  Пресметува тежина на класа
class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_generator.classes), y=train_generator.classes)
class_weights = {i: class_weights[i] for i in range(len(class_weights))}

#  Тренирање модел
history = model.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=37,
    class_weight=class_weights,
    callbacks=[checkpoint, early_stopping, reduce_lr, lr_callback]
)

#  Вчитува најдобар модел
best_model = tf.keras.models.load_model(checkpoint_filepath)

# Евалуира најдобар модел
loss, accuracy = best_model.evaluate(validation_generator, verbose=0)
print(f'Validation loss: {loss}, Validation accuracy: {accuracy * 100:.2f}%')

plt.figure(figsize=(10, 5))
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(['Training Accuracy', 'Validation Accuracy'])
plt.show()

#  Плот за loss values при тренинг и валидација
plt.figure(figsize=(10, 5))
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend(['Training Loss', 'Validation Loss'])
plt.show()

#  Генерира предикции и пресметува конфузиона матрица
validation_steps = validation_generator.samples // validation_generator.batch_size
y_pred = best_model.predict(validation_generator, steps=validation_steps, verbose=1)
y_pred_labels = (y_pred > 0.5).astype(int)
y_true = validation_generator.classes[:len(y_pred_labels)]

conf_matrix = confusion_matrix(y_true, y_pred_labels)
class_names = ['benign', 'malignant']

plt.figure(figsize=(12, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

# Печати извештај на класификација 
report = classification_report(y_true, y_pred_labels, target_names=class_names)
print(report)

!pip install --upgrade tensorflow
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, GlobalAveragePooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau
import os, shutil
from tensorflow.keras.applications import EfficientNetB5
from tensorflow.keras.optimizers import Adam
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import confusion_matrix, classification_report
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import seaborn as sns
from sklearn.model_selection import train_test_split
import shutil
import albumentations as A

#  Дефинира основен извор на податоци
from google.colab import drive
drive.mount('/content/drive')
main_directory = '/content/drive/My Drive/Colab_Notebooks'
data_folder = os.path.join('/content/drive/My Drive','breast')

# Креирај база за тренирање и валидација на податоците
training_folder = os.path.join(main_directory, 'train')
validation_folder = os.path.join(main_directory, 'validation')

os.makedirs(training_folder, exist_ok=True)
os.makedirs(validation_folder, exist_ok=True)

# #Аугментација на генерална дата за бинарна класификација
train_datagen = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.3,
    zoom_range=0.3,
    horizontal_flip=True,
    rotation_range=40,
    width_shift_range=0.3,
    height_shift_range=0.3,
    brightness_range=[0.9, 1.1],
)

val_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.5)

training_generator = training_datagen.flow_from_directory(
    training_folder,
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary'
)

validation_generator = validation_datagen.flow_from_directory(
    validation_folder,
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary',
    subset='training'  # Use 50% of the validation set for actual validation during training
)

test_generator = validation_datagen.flow_from_directory(
    validation_folder,
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary',
    subset='validation',  # Use the remaining 50% as a test set
    shuffle=False  # Important: do not shuffle to keep labels aligned for evaluation
)

# Рекреира архитектура на модел
model = Sequential([
    EfficientNetB5(input_shape=(224, 224, 3), include_top=False, weights='imagenet'),
    GlobalAveragePooling2D(),
    Dropout(0.8),
    Dense(1, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.01))
])

# Гради модел
model.build((None, 224, 224, 3))
# Вчитува тежини од зачуван модел
model.load_weights='/content/drive/MyDrive/efficientnet_checkpoints/best_model.keras'
# Извршува re-compile на моделот
model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])

# Дефинира callbacks
checkpoint_filepath = '/content/drive/MyDrive/efficientnet_checkpoints/best_model.keras'
checkpoint = ModelCheckpoint(
    filepath=checkpoint_filepath,
    save_weights_only=False,
    monitor='val_loss',
    mode='min',
    save_best_only=True,
    verbose=1
)

early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)

def scheduler(epoch, lr):
    if epoch < 10:
        return float(lr)
    else:
        return float(lr * tf.math.exp(-0.1))

lr_callback = LearningRateScheduler(scheduler)

#  ПРесметува тежина на класа
class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_generator.classes), y=train_generator.classes)
class_weights = {i: class_weights[i] for i in range(len(class_weights))}

#  Продолжува со тренирање модел
remaining_epochs = 27  
history = model.fit(
    training_generator,
    validation_data=validation_generator,
    epochs=remaining_epochs,
    class_weight=class_weights,
    callbacks=[checkpoint, early_stopping, reduce_lr, lr_callback]
)

#  Евалуира најдобар модел на сетот за валидација 
val_loss, val_accuracy = best_model.evaluate(validation_generator, verbose=0)
print(f'Validation loss: {val_loss}, Validation accuracy: {val_accuracy * 100:.2f}%')

# Евалуира најдобар модел на сетот за тренинг 
test_loss, test_accuracy = best_model.evaluate(test_generator, verbose=0)
print(f'Test loss: {test_loss}, Test accuracy: {test_accuracy * 100:.2f}%')

#  Генерира предикции на тест сетот
test_steps = test_generator.samples // test_generator.batch_size
y_pred = best_model.predict(test_generator, steps=test_steps, verbose=1)
y_pred_labels = (y_pred > 0.5).astype(int)
y_true = test_generator.classes[:len(y_pred_labels)]

#  Пресметува конфузиона матрица на тест сетот
conf_matrix = confusion_matrix(y_true, y_pred_labels)
class_names = ['benign', 'malignant']

plt.figure(figsize=(12, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix - Test Set')
plt.show()

#  Печати извештај за класификација на тест сетот
report = classification_report(y_true, y_pred_labels, target_names=class_names)
print(report)

#  Плот на тренинг и валидациони вредности на точност
plt.figure(figsize=(10, 5))
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(['Training Accuracy', 'Validation Accuracy'])
plt.show()

#  Плот на тренинг и валидациони вредности на загуба
plt.figure(figsize=(10, 5))
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend(['Training Loss', 'Validation Loss'])
plt.show()


!pip install --upgrade tensorflow
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, GlobalAveragePooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau
import os, shutil
from tensorflow.keras.applications import EfficientNetB5
from tensorflow.keras.optimizers import Adam
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import confusion_matrix, classification_report
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import seaborn as sns
from sklearn.model_selection import train_test_split
import shutil
import albumentations as A

# Дефинира основен извор на податоци
from google.colab import drive
drive.mount('/content/drive')
main_directory = '/content/drive/My Drive/Colab_Notebooks'
data_folder = os.path.join('/content/drive/My Drive','breast')

# Тестира аугментациски податоци
validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, validation_split=0.5)

# Вчитува тест сет 
test_generator = validation_datagen.flow_from_directory(
    validation_folder,
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary',
    subset='validation',  # Use the remaining 50% as the test set
    shuffle=False  # Important: do not shuffle to keep labels aligned for evaluation
)

# Рекреира модел на архитектура
model = Sequential([
    EfficientNetB5(input_shape=(224, 224, 3), include_top=False, weights='imagenet'),
    GlobalAveragePooling2D(),
    Dropout(0.8),
    Dense(1, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.01))
])

# Гради модел
model.build((None, 224, 224, 3))

# Вчитува зачувани тежини наместо оние на цел модел
model.load_weights('/content/drive/MyDrive/efficientnet_checkpoints/best_model.keras')

# Повторен сompile на моделот 
model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])


#Евалуира најдобар модел на тест сетот
test_loss, test_accuracy = model.evaluate(test_generator, verbose=0)
print(f'Test loss: {test_loss}, Test accuracy: {test_accuracy * 100:.2f}%')

#Генерира предикции на тест сетот
#test_steps = test_generator.samples // test_generator.batch_size
#y_pred = model.predict(test_generator, steps=test_steps, verbose=1)
y_pred = model.predict(test_generator)
y_pred_labels = (y_pred > 0.5).astype(int)
y_true = test_generator.classes[:len(y_pred_labels)]

#Пресметува конфузиона матрица за тест сет
conf_matrix = confusion_matrix(y_true, y_pred_labels)
class_names = ['benign', 'malignant']

# Плот на конфузиона матрица
plt.figure(figsize=(12, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names, annot_kws={"size": 34})
plt.xlabel('Predicted Label',fontsize=18)
plt.ylabel('True Label',fontsize=18)
plt.title('Confusion Matrix - Test Set',fontsize=18)
plt.xticks(fontsize=16)
plt.yticks(fontsize=16)
plt.show()

# Печати извештај на класификација за тест сет
report = classification_report(y_true, y_pred_labels, target_names=class_names)
print(report)
